# Gemini AI Caching System

## Overview

The Gemini AI caching system prevents duplicate API calls by storing responses in IndexedDB. This significantly reduces token usage and improves response times for repeated queries.

## Features

- **Automatic Caching**: All Gemini AI responses are automatically cached (except for image-based tasks)
- **Smart Cache Keys**: Normalized payload hashing ensures consistent cache keys
- **Automatic Expiration**: Cache entries expire after 24 hours (configurable)
- **Size Management**: Maximum 1000 cache entries with automatic eviction of oldest entries
- **Periodic Cleanup**: Automatic cleanup of expired entries every hour
- **Task-Specific Control**: Certain tasks (like `parseReceipt`) are excluded from caching

## How It Works

1. **Cache Check**: Before making an API call, the system checks if a cached response exists
2. **Cache Hit**: If found and not expired, the cached response is returned immediately
3. **Cache Miss**: If not found, the API call is made and the response is cached
4. **Automatic Cleanup**: Expired entries are automatically removed

## Cache Configuration

### Default Settings

- **TTL (Time To Live)**: 24 hours
- **Max Cache Size**: 1000 entries
- **Cleanup Interval**: 1 hour
- **Non-Cacheable Tasks**: `parseReceipt` (image-based tasks)

### Cache Storage

- **Database**: IndexedDB (`gemini-cache`)
- **Store**: `responses`
- **Persistence**: Survives browser restarts

## Usage

The caching is completely transparent - no code changes needed in your components. The cache is automatically used by all Gemini AI functions:

```typescript
import { getAnalysisInsights, generateReportSummary } from '../lib/gemini';

// First call - makes API request and caches response
const insight1 = await getAnalysisInsights(question, context, data);

// Second call with same parameters - returns cached response (no API call)
const insight2 = await getAnalysisInsights(question, context, data);
```

## Cache Management

### Programmatic Access

```typescript
import { geminiCache } from '../lib/geminiCache';

// Get cache statistics
const stats = await geminiCache.getStats();
console.log(`Total entries: ${stats.total}, Expired: ${stats.expired}`);

// Clear cache for a specific task
await geminiCache.clearTask('getAnalysisInsights');

// Clear all cache entries
await geminiCache.clearAll();
```

### Cache Statistics

The `getStats()` method returns:
- `total`: Total number of cache entries
- `expired`: Number of expired entries (will be cleaned up)

## Cache Key Generation

Cache keys are generated by:
1. Normalizing the payload (sorting object keys, handling arrays)
2. Creating a hash from `task:normalizedPayload`
3. Format: `gemini:{task}:{hash}`

This ensures that identical requests (even with different key ordering) use the same cache entry.

## Performance Benefits

- **Reduced API Calls**: Identical requests return instantly from cache
- **Lower Token Usage**: No API calls for cached responses
- **Faster Response Times**: Cache hits are typically < 10ms vs 1-3s for API calls
- **Cost Savings**: Significant reduction in Gemini API costs

## Limitations

1. **Image-based Tasks**: `parseReceipt` is not cached (each image is unique)
2. **Cache Size**: Limited to 1000 entries (oldest entries are evicted)
3. **Browser Storage**: Cache is stored locally in IndexedDB (per browser)

## Troubleshooting

### Cache Not Working

1. Check browser console for IndexedDB errors
2. Verify IndexedDB is enabled in browser settings
3. Check if task is in `NON_CACHEABLE_TASKS` list

### Clearing Cache

```typescript
// Clear all cache
await geminiCache.clearAll();

// Or clear specific task
await geminiCache.clearTask('getAnalysisInsights');
```

### Debug Logging

Cache operations are logged at debug level:
- Cache hits: `logger.debug('Cache hit for task: ...')`
- Cache stores: `logger.debug('Cached response for task: ...')`
- Cache evictions: `logger.debug('Evicted N oldest cache entries...')`

## Future Enhancements

Potential improvements:
- Configurable TTL per task type
- Cache warming strategies
- Cache compression for large responses
- Cross-tab cache synchronization
- Cache analytics dashboard
